summary(data)
View(data)
data = read.csv("Geronimo_statistics.csv", stringsAsFactors = FALSE)
View(data)
summary(data)
sum= summary(data)
plot(sum)
sum= summary(data)
sum= summary(data)
sum= summary(data)
table(sum)
summary(data)
speed_comparison= read.csv("Geronimo_statistics.csv", stringsAsFactors = FALSE)
summary(speed_comparison$Archiving.50.with.Outlook)
s1= summary(speed_comparison$Archiving.50.with.Outlook)
hist()
s1= summary(speed_comparison$Archiving.50.with.Outlook)
hist(s1)
s1= summary(speed_comparison$Archiving.50.with.Outlook)
si
s1= summary(speed_comparison$Archiving.50.with.Outlook)
s1
hist(s1)
s1= summary(speed_comparison$Archiving.50.with.Outlook)
s2= summary(speed_comparison$Archiving.50.with.Gmail)
s1= summary(speed_comparison$Archiving.50.with.Outlook)
s2= summary(speed_comparison$Archiving.50.with.Gmail)
plot(s1, s2)
s1= summary(speed_comparison$Archiving.50.with.Outlook)
s2= summary(speed_comparison$Archiving.50.with.Gmail)
plot(as.numeric(s1), as.numeric(s2))
s1= summary(speed_comparison$Archiving.50.with.Outlook)
s2= summary(speed_comparison$Archiving.50.with.Gmail)
hist(as.numeric(s1), as.numeric(s2))
hist(speed_comparison, col = "green")
speed_comparison= as.data.frame(speed_comparison)
hist(speed_comparison, col = "green")
s1= summary(speed_comparison$Archiving.50.with.Outlook)
s2= summary(speed_comparison$Archiving.50.with.Gmail)
class(speed_comparison$Archiving.50.with.Outlook)
speed_comparison= as.data.matrix(speed_comparison)
speed_comparison= as.matrix(speed_comparison)
hist(speed_comparison, col = "green")
s1= summary(speed_comparison$Archiving.50.with.Outlook)
#s1= summary(speed_comparison$Archiving.50.with.Outlook)
#s2= summary(speed_comparison$Archiving.50.with.Gmail)
View(speed_comparison)
class(speed_comparison$Archiving.50.with.Outlook)
summary(speed_comparison)
library(Hmisc)
describe(speed_comparison)
library(Hmisc)
describe(speed_comparison)
M1 <- cor(speed_comparison,speed_comparison)
# plot of 1-15 variables with 16-30 variables
library(corrplot)
#M <- cor(mtcars)
corrplot(M1, method="circle", type = "lower")
# plot of 1-15 variables with 16-30 variables
library(corrplot)
#M <- cor(mtcars)
corrplot(M1, method="circle", type = "lower")
speed_comparison= read.csv("Geronimo_statistics.csv", stringsAsFactors = FALSE)
speed_comparison= as.matrix(speed_comparison)
summary(speed_comparison)
M1 <- cor(speed_comparison,speed_comparison)
library(corrplot)
corrplot(M1, method="circle", type = "upper")
M1 <- cor(speed_comparison,speed_comparison)
average_speed <- c(50.67,33.75,21.12 )
barplot(average_speed)
average_speed <- c(50.67,33.75,21.12 )
barplot(average_speed, main = " plot of average speed across 3 apps ", xlab = "Outlook -> Gmail -> Geronimo")
average_speed <- c(50.67,33.75,21.12 )
barplot(average_speed, main = " plot of average speed across 3 apps ", xlab = "Outlook -> Gmail -> Geronimo", ylab = " average speed")
average_speed <- c(50.67,33.75,21.12 )
barplot(average_speed, main = " plot of average speed across 3 apps ", xlab = "Outlook -> Gmail -> Geronimo", ylab = " average speed", col = "green")
summary(speed_comparison)
average_speed <- c(50.67,33.75,21.12 )
barplot(average_speed, main = " plot of average time in seconds across 3 apps ", xlab = "Outlook -> Gmail -> Geronimo", ylab = " average time in seconds", col = "green")
average_speed <- c(50.67,33.75,21.12 )
hist(average_speed, main = " plot of average time in seconds across 3 apps ", xlab = "Outlook -> Gmail -> Geronimo", ylab = " average time in seconds", col = "green")
average_speed <- c(50.67,33.75,21.12 )
barplot(average_speed, main = " plot of average time in seconds across 3 apps ", xlab = "Outlook -> Gmail -> Geronimo", ylab = " average time in seconds", col = "green")
max_time<- c(72.70,52.10 ,34.00 )
barplot(max_time, main = " plot of max time in seconds across 3 apps ", xlab = "Outlook -> Gmail -> Geronimo", ylab = " max time in seconds", col = "green")
average_speed <- c(50.67,33.75,21.12 )
barplot(average_speed, main = " plot of average time in seconds across 3 apps for moving 50 emails", xlab = "Outlook -> Gmail -> Geronimo", ylab = " average time in seconds", col = "green")
max_time<- c(72.70,52.10 ,34.00 )
barplot(max_time, main = " plot of max time in seconds across 3 apps for moving 50 emails ", xlab = "Outlook -> Gmail -> Geronimo", ylab = " max time in seconds", col = "green")
min_time<- c(38.36, 25.30, 13.31)
barplot(min_time, main = " plot of min time in seconds across 3 apps for moving 50 emails ", xlab = "Outlook -> Gmail -> Geronimo", ylab = " min time in seconds", col = "green")
average_speed <- c(50.67,33.75,21.12 )
barplot(average_speed, main = " plot of average time in seconds across 3 apps for archiving 50 emails", xlab = "Outlook -> Gmail -> Geronimo", ylab = " average time in seconds", col = "green")
average_speed <- c(50.67,33.75,21.12 )
barplot(average_speed, main = " plot of average time in seconds across 3 apps for archiving 50 emails", xlab = "Outlook -> Gmail -> Geronimo", ylab = " average time in seconds", col = "green")
max_time<- c(72.70,52.10 ,34.00 )
barplot(max_time, main = " plot of max time in seconds across 3 apps for archiving 50 emails ", xlab = "Outlook -> Gmail -> Geronimo", ylab = " max time in seconds", col = "green")
min_time<- c(38.36, 25.30, 13.31)
barplot(min_time, main = " plot of min time in seconds across 3 apps for archiving  50 emails ", xlab = "Outlook -> Gmail -> Geronimo", ylab = " min time in seconds", col = "green")
M1 <- cor(speed_comparison,speed_comparison)
library(corrplot)
corrplot(M1, method="circle", type = "upper")
average_speed <- c(50.67,33.75,21.12 )
barplot(average_speed, main = " plot of average time in seconds across 3 apps for archiving 50 emails", xlab = "Outlook -> Gmail -> Geronimo", ylab = " average time in seconds", col = "red")
max_time<- c(72.70,52.10 ,34.00 )
barplot(max_time, main = " plot of max time in seconds across 3 apps for archiving 50 emails ", xlab = "Outlook -> Gmail -> Geronimo", ylab = " max time in seconds", col = "red")
min_time<- c(38.36, 25.30, 13.31)
barplot(min_time, main = " plot of min time in seconds across 3 apps for archiving  50 emails ", xlab = "Outlook -> Gmail -> Geronimo", ylab = " min time in seconds", col = "red")
average_time2<- c(18.32, 17.71, 9.853)
barplot(average_time2, main = " plot of average time in seconds across 3 apps for moving 20 emails", xlab = "Outlook -> Gmail -> Geronimo", ylab = " average time in seconds", col = "green")
max_time2<- c(33.51,26.05,14.290)
barplot(max_time2, main = " plot of max time in seconds across 3 apps for moving 20 emails ", xlab = "Outlook -> Gmail -> Geronimo", ylab = " max time in seconds", col = "green")
min_time2<- c(13.30,13.70,7.140 )
barplot(min_time2, main = " plot of min time in seconds across 3 apps for moving 20 emails ", xlab = "Outlook -> Gmail -> Geronimo", ylab = " min time in seconds", col = "green")
M1 <- cor(speed_comparison,speed_comparison)
M1
subgraph1 <- induced.subgraph(wiki_network, V(wiki_network)[1:80])
library(igraph)
subgraph1 <- induced.subgraph(wiki_network, V(wiki_network)[1:80])
## Put your code here
network= read.graph("Internet_AS.dat", format = "edgelist")
xmax=max(degree(network))
degree_range= as.numeric(1:xmax)
degree_dist <- degree.distribution(network, cumulative = FALSE)[degree_range]
nonzero.position <- which(degree_dist > 0)
degree_dist <- degree_dist[nonzero.position]
degree_range <- degree_range[nonzero.position]
cum_degree_range <- degree_range+1
plot(degree_dist, log = "xy", main = "PDF", xlab = "node degree (log)", ylab = "frequency (log)", col= "blue")
cum_degree_dist <- cumsum(degree_dist)
plot(cum_degree_dist, log = "xy", main = "CDF", xlab = "node degree (log)", ylab = "frequency (log)", col="blue")
## fit linear regression for PDF
reg <- lm(log(degree_dist) ~ log(degree_range))
coefficients <- coef(reg)
func_powerlaw <- function(x) exp(coefficients[[1]] + coefficients[[2]] * log(x))
alpha <- -coefficients[[2]]
print(alpha)
# plot PDF and its estimation
plot(degree_dist ~ degree_range, log = "xy", main = "PDF", xlab = "node degree (log)", ylab = "frequency")
curve(func_powerlaw, col = "red", add = TRUE, n = length(degree_range))
# fit linear regression for CDF
reg <- lm(log(cum_degree_dist) ~ log(cum_degree_range))
coefficients <- coef(reg)
func_powerlaw <- function(x) exp(coefficients[[1]] + coefficients[[2]] * log(x))
alpha2 <- -coefficients[[2]]
alpha2
# fit linear regression for CDF
reg <- lm(log(cum_degree_dist) ~ log(cum_degree_range))
coefficients <- coef(reg)
func_powerlaw <- function(x) exp(coefficients[[1]] + coefficients[[2]] * log(x))
alpha2 <- -coefficients[[2]]
alpha2
# plot cDF and its estimation
plot(cum_degree_dist ~ cum_degree_range, log = "xy", main = "CDF", xlab = "node degree (log)", ylab = "frequency", col= "blue")
curve(func_powerlaw, col = "red", add = TRUE, n = length(cum_degree_range))
## Put your code here
d <- degree(network)
fit <- power.law.fit(d, NULL, implementation = "plfit")
alpha <- fit$alpha
xmin <- fit$xmin
C <- (alpha-1)*xmin^(alpha-1)
alpha
xmin
## Put your code here
par(mfrow=c(2,1))
fit_pdf <- function(x) return(C*x^(-alpha))
plot(degree_range,degree_dist, log = "xy", main = "PDF", xlab = "node degree (lo)", ylab = "frequency", col= "blue")
#lines(x, x^(-alpha), col="green")
par(new=TRUE)
curve(fit_pdf,from=xmin,to=xmax, log="xy", col = "red", add = FALSE, n = length(degree_range))
## Put your code here
wiki_network = read.graph("Wiki-Vote.txt", format = "edgelist")
vcount(wiki_network)
ecount(wiki_network)
## Put your code here
sum(is.loop(wiki_network), na.rm = TRUE)
## Put your code here
reciprocity(wiki_network)*ecount(wiki_network)/2
## Put your code here
degree_dist2 <- degree.distribution(wiki_network, mode='all')
plot(degree.distribution(wiki_network, mode= 'all')[which(degree_dist2>0)], log= 'xy', main = "PDF", xlab = "degree", ylab = "frequency", col="blue")
sum(degree(wiki_network)>1)
sum(degree(wiki_network)>15)
## Put your code here
components <- clusters(wiki_network, mode = "strong")
components$no
#compoenets$csize
subgraph1 <- induced.subgraph(wiki_network, V(wiki_network)[1:80])
dgin <- degree(subgraph1, mode = "in")
dgout <- degree(subgraph1, mode = "out")
V(subgraph1)[which(dgin>dgout)]$color <- "red"
V(subgraph1)[which(dgin==dgout)]$color <- "green"
V(subgraph1)[which(dgin<dgout)]$color <- "blue"
tr <- transitivity(subgraph1, type = "local", isolates = "zero")
V(subgraph)$size <- ifelse(tr==1, 30, 10)
subgraph1 <- induced.subgraph(wiki_network, V(wiki_network)[1:80])
dgin <- degree(subgraph1, mode = "in")
dgout <- degree(subgraph1, mode = "out")
V(subgraph1)[which(dgin>dgout)]$color <- "red"
V(subgraph1)[which(dgin==dgout)]$color <- "green"
V(subgraph1)[which(dgin<dgout)]$color <- "blue"
tr <- transitivity(subgraph1, type = "local", isolates = "zero")
V(subgraph1)$size <- ifelse(tr==1, 30, 10)
plot(subgraph1)
## Put your code here
con_com <- clusters(subgraph1, mode = "weak")
V(subgraph1)$membership <- clusters(subgraph1, mode = "weak")$membership
subg_new <- induced.subgraph(subgraph1, V(subgraph1)[membership==4])
dpath <- get.diameter(subg_new)
E(subg_new, path = dpath)$color <- "black"
V(subg_new)$color <- " green"
plot(subg_new, vertex.size= 10)
path.length.hist(subg_new, directed = TRUE)
## Put your code here
# get average neighbour degree
avnd <- graph.knn(subgraph1)$knn
# get node degree
nd <- degree(subgraph1)
# scatter plot
plot(avnd, nd, xlab = "node degree", ylab = "average neighbour degree")
agg_avnd <- c()
index = 1
for (d in unique(nd)) {
agg_avnd[index] <- sum(avnd[which(nd==d)])/length(which(nd==d))
index = index + 1
}
plot(unique(nd), agg_avnd, main = "Aggregated plot", xlab = "node degree", ylab = "average neighbour")
## Put your code here
# get local clustering coeff
lcc<- transitivity(subgraph1, type = "local", isolates = "zero")
# get node degree
nd <- degree(subgraph1)
# scatter plot
plot(lcc, nd, xlab = "node degree", ylab = "local clustering coeff")
agg_lcc <- c()
index = 1
for (d in unique(nd)) {
agg_lcc[index] <- sum(lcc[which(nd==d)])/length(which(nd==d))
index = index + 1
}
plot(unique(nd), agg_lcc, main = "Aggregated plot", xlab = "node degree", ylab = "average local clustering coeff")
library(igraph)
## Put your code here
read_graph("pcb.gdf", format = c("graphml"))
pwd
getwd()
setwd("I:\HSE\HSE\Big Data Systems\Predictive Modeling workshops ")
setwd("I:/HSE\HSE/Big Data Systems/Predictive Modeling workshops ")
setwd("I:/HSE/HSE/Big Data Systems/Predictive Modeling workshops ")
install.packages("AppliedPredictiveModeling ")
install.packages("AppliedPredictiveModeling")
install.packages("e1071")
install.packages("lattice")
install.packages("corrplot")
install.packages("caret")
library(caret)
library(corrplot)
library(e1071)
library(lattice)
library(AppliedPredictiveModeling)
source('I:/HSE/HSE/Big Data Systems/Predictive Modeling workshops/workshop2.R')
data(segmentationOriginal)
structure(segmentationOriginal)
summary(segmentationOriginal)
segData= subset(segmentationOriginal, Case=="Train")
names(segmentationOriginal)
dim(segmentationOriginal)
Cell <-(segData$Cell)
Class <- segData$Class
Case <- segData$Case
segData <- segData[,-(1:3)]
statusColNum <-grep("Status", names(segData))
segData <- segData[,-statusColNum]
dim(segData)
skewness(segData$AreaCh1)
skewValues<- apply(segData,2, skewness)
head(skewValues)
hist(segData$AvgIntenCh1, breaks = 100, main = "Histogram of Segmentation Original")
hist(segData$AngleCh1, breaks = 100, main = "Histogram of Segmentation Original")
ch1ArearTrans <-BoxCoxTrans(segData$AreaCh1)
ch1ArearTrans$skewness
ch1ArearTrans$summary
ch1ArearTrans$lambda
head(segData$AreaCh1)
myA= predict(ch1ArearTrans, head(segData$AreaCh1))
myA
skewness(myA)
pcaobj<- prcomp()
pcaobj<- prcomp(segData,center = TRUE, scale. = TRUE)
library(caret)
library(corrplot)
library(e1071)
library(lattice)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
structure(segmentationOriginal)
summary(segmentationOriginal)
segData= subset(segmentationOriginal, Case=="Train")
names(segmentationOriginal)
dim(segmentationOriginal)
Cell <-(segData$Cell)
Class <- segData$Class
Case <- segData$Case
segData <- segData[,-(1:3)]
statusColNum <-grep("Status", names(segData))
segData <- segData[,-statusColNum]
dim(segData)
skewness(segData$AreaCh1)
skewValues<- apply(segData,2, skewness)
head(skewValues)
hist(segData$AvgIntenCh1, breaks = 100, main = "Histogram of Segmentation Original")
hist(segData$AngleCh1, breaks = 100, main = "Histogram of Segmentation Original")
ch1ArearTrans <-BoxCoxTrans(segData$AreaCh1)
ch1ArearTrans$skewness
ch1ArearTrans$summary
ch1ArearTrans$lambda
head(segData$AreaCh1)
myA= predict(ch1ArearTrans, head(segData$AreaCh1))
myA
skewness(myA)
pcaobj<- prcomp(segData,center = TRUE, scale. = TRUE)
pcaobj<- prcomp(segData,center = TRUE, scale. = TRUE)
percentVariance <- pcaobj$sdev ^2/sum(pcaobj$sdev^2)*100
pcaobj<- prcomp(segData,center = TRUE, scale. = TRUE)
percentVariance <- pcaobj$sdev ^2/sum(pcaobj$sdev^2)*100
percentVariance[1:3]
head(pcaobj$x[,1:5])
head(pcaobj$x[,1:3])
pcaobj<- prcomp(segData,center = TRUE, scale. = TRUE)
percentVariance <- pcaobj$sdev ^2/sum(pcaobj$sdev^2)*100
percentVariance[1:3]
View(segData)
View(segData)
pcaobj$x
preProcess(segData,method = c("BoxCox","center", "scale", "pca"))
trans <- preProcess(segData,method = c("BoxCox","center", "scale", "pca"))
trans
transformed <- predict(tran, segData)
transformed <- predict(trans, segData)
head(transformed[,1:5])
nearZeroVar(segData)
corealtions <-cor(segData)
corealtions <-cor(segData)
dim(corealtions)
corealtions[1:5,1:5]
corrplot(corealtions, order = 'hclust')
highCorr <-  findCorrelation(corealtions,cutoff = 0.75)
length(hgihCorr)
highCorr <-  findCorrelation(corealtions,cutoff = 0.75)
length(highCorr)
head(highCorr)
filteredSegData <- segData[, -highCorr]
filteredSegData <- segData[, -highCorr]
filteredSegData <- segData[, -highCorr]
filteredSegData
library(caret)
library(corrplot)
library(e1071)
library(lattice)
library(AppliedPredictiveModeling)
library(caret)
library(corrplot)
library(e1071)
library(lattice)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
structure(segmentationOriginal)
summary(segmentationOriginal)
segData= subset(segmentationOriginal, Case=="Train")
names(segmentationOriginal)
dim(segmentationOriginal)
Cell <-(segData$Cell)
Class <- segData$Class
Case <- segData$Case
segData <- segData[,-(1:3)]
statusColNum <-grep("Status", names(segData))
segData <- segData[,-statusColNum]
dim(segData)
skewness(segData$AreaCh1)
skewValues<- apply(segData,2, skewness)
head(skewValues)
hist(segData$AvgIntenCh1, breaks = 100, main = "Histogram of Segmentation Original")
hist(segData$AngleCh1, breaks = 100, main = "Histogram of Segmentation Original")
ch1ArearTrans <-BoxCoxTrans(segData$AreaCh1)
ch1ArearTrans$skewness
ch1ArearTrans$summary
ch1ArearTrans$lambda
head(segData$AreaCh1)
myA= predict(ch1ArearTrans, head(segData$AreaCh1))
myA
skewness(myA)
pcaobj<- prcomp(segData,center = TRUE, scale. = TRUE)
percentVariance <- pcaobj$sdev ^2/sum(pcaobj$sdev^2)*100
percentVariance[1:3]
head([,1:5])
head(pcaobj[,1:5])
pcaobj<- prcomp(segData,center = TRUE, scale. = TRUE)
percentVariance <- pcaobj$sdev ^2/sum(pcaobj$sdev^2)*100
percentVariance[1:3]
head(pcaobj[,1:5])
library(caret)
library(corrplot)
library(e1071)
library(lattice)
library(AppliedPredictiveModeling)
## Retain the original training set
segTrain <- subset(segmentationOriginal, Case == "Train")
## Remove the first three columns (identifier columns)
segTrainX <- segTrain[, -(1:3)]
segTrainClass <- segTrain$Class
library(caret)
library(corrplot)
library(e1071)
library(lattice)
library(AppliedPredictiveModeling)
## Retain the original training set
segTrain <- subset(segmentationOriginal, Case == "Train")
## Remove the first three columns (identifier columns)
segTrainX <- segTrain[, -(1:3)]
segTrainClass <- segTrain$Class
## Use caret's preProcess function to transform for skewness
segPP <- preProcess(segTrainX, method = "BoxCox")
## Apply the transformations
segTrainTrans <- predict(segPP, segTrainX)
xyplot(AvgIntenCh1 ~ EntropyIntenCh1,
data = segTrainTrans,
groups = segTrain$Class,
xlab = "Channel 1 Fiber Width",
ylab = "Intensity Entropy Channel 1",
auto.key = list(columns = 2),
type = c("p", "g"),
main = "Original Data",
aspect = 1)
library(caret)
library(corrplot)
library(e1071)
library(lattice)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
structure(segmentationOriginal)
summary(segmentationOriginal)
segData= subset(segmentationOriginal, Case=="Train")
names(segmentationOriginal)
dim(segmentationOriginal)
Cell <-(segData$Cell)
Class <- segData$Class
Case <- segData$Case
segData <- segData[,-(1:3)]
statusColNum <-grep("Status", names(segData))
segData <- segData[,-statusColNum]
dim(segData)
skewness(segData$AreaCh1)
skewValues<- apply(segData,2, skewness)
head(skewValues)
hist(segData$AvgIntenCh1, breaks = 100, main = "Histogram of Segmentation Original")
hist(segData$AngleCh1, breaks = 100, main = "Histogram of Segmentation Original")
ch1ArearTrans <-BoxCoxTrans(segData$AreaCh1)
ch1ArearTrans$skewness
ch1ArearTrans$summary
ch1ArearTrans$lambda
head(segData$AreaCh1)
myA= predict(ch1ArearTrans, head(segData$AreaCh1))
myA
skewness(myA)
pcaobj<- prcomp(segData,center = TRUE, scale. = TRUE)
percentVariance <- pcaobj$sdev ^2/sum(pcaobj$sdev^2)*100
percentVariance[1:3]
pcaobj$x
head(pcaobj$x[,1:3])
trans <- preProcess(segData,method = c("BoxCox","center", "scale", "pca"))
trans
transformed <- predict(trans, segData)
head(transformed[,1:5])
nearZeroVar(segData)
corealtions <-cor(segData)
dim(corealtions)
corealtions[1:5,1:5]
corrplot(corealtions, order = 'hclust')
highCorr <-  findCorrelation(corealtions,cutoff = 0.75)
length(highCorr)
head(highCorr)
filteredSegData <- segData[, -highCorr]
filteredSegData
pr <- prcomp(~ AvgIntenCh1 + EntropyIntenCh1,
data = segTrainTrans,
scale. = TRUE)
xyplot(PC2 ~ PC1,
data = as.data.frame(pr$x),
groups = segTrain$Class,
xlab = "Principal Component #1",
ylab = "Principal Component #2",
main = "Transformed",
xlim = extendrange(pr$x),
ylim = extendrange(pr$x),
type = c("p", "g"),
aspect = 1)
segTrain$Class
isZV <- apply(segTrainX, 2, function(x) length(unique(x)) == 1)
segTrainX <- segTrainX[, !isZV]
segPP <- preProcess(segTrainX, c("BoxCox", "center", "scale"))
segTrainTrans <- predict(segPP, segTrainX)
segPCA <- prcomp(segTrainTrans, center = TRUE, scale. = TRUE)
## Plot a scatterplot matrix of the first three components
transparentTheme(pchSize = .8, trans = .3)
panelRange <- extendrange(segPCA$x[, 1:3])
splom(as.data.frame(segPCA$x[, 1:3]),
groups = segTrainClass,
type = c("p", "g"),
as.table = TRUE,
auto.key = list(columns = 2),
prepanel.limits = function(x) panelRange)
